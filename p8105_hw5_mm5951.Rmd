---
title: "Homework 5"
author: "mm5951"
date: "`r Sys.Date()`"
output: github_document
---

```{r, include = FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Solutions provided by teaching team.


## Problem 2

### Data wrangling & description 

First, I import the dataset using `read_csv()` and rename empty observations to "na" ("", "Unknown"). To describe the raw data, I use the `skimr::skim()` function.

```{r, warning = FALSE}
homicide_df_raw = read_csv("./data/homicide-data.csv", na = c("","Unknown"))

skimr::skim(homicide_df_raw)
```

The "homicide_df_raw" dataset contains `r ncol(homicide_df_raw)` variables and `r nrow(homicide_df_raw)` observations. Details on the nature of its variables and summary values are found in the outputs above.

Then, I wrangle data as per problem instructions. This includes:

* Create a new "city_state" variable (e.g. “Baltimore, MD”) with `mutate()` and order by alphabetical orden using `str_c()`.
* Create a new "resolution" variable using the `case_when()` syntaxis, indicating whehter a case is resolved or not (those for which the disposition is “Closed without arrest” or “Open/No arrest”).
* Note one entry "Tulsa, AL" is excluded using `filter()`, as it is unclear whether it refers to Tulsa, Oklahoma or Birmingham, Alabama (this entry becomes apparent on the next section, under the "US_summary" data frame, and is then retroactively amended).

```{r}
homicide_df = homicide_df_raw %>% 
  mutate(city_state = str_c(city, state, sep = ", "),
         resolution = case_when(
           disposition == "Closed without arrest" ~ "unsolved",
           disposition == "Open/No arrest" ~ "unsolved",
           disposition == "Closed by arrest" ~ "solved"
         )) %>% 
  relocate(city_state) %>% 
  filter(city_state != "Tulsa, AL")
```

Then, I summarize within cities using `group_by()` to obtain the total number of homicides ("n") and the number of unsolved homicides ("unsolved") in a table using `knitr::kable()`. 

```{r}
US_summary = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    n = n(),
    unsolved = sum(resolution == "unsolved"),
      ) %>% 
  knitr::kable()

US_summary
```


### Baltimore city estimates 

Next, I use the `prop.test` function to perform a test of equal proportions *(that is, testing the null that the proportions (probabilities of success) in several groups are the same, or that they equal certain given values.)*

More specifically, for the city of Baltimore, MD, I estimate the **proportion of homicides that are unsolved**. To do so, first a summary dataframe is generated containing the sum of "unsolved" crimes and the overall sample size ("n"). Then, 
A "baltimore_test" R object (a list) is generated as an output of the `prop.test`, to which then I apply `broom::tidy`. It contains the estimated proportion and confidence intervals from the test of equal proportions.

```{r}
baltimore_df = homicide_df %>% 
  filter(city_state == "Baltimore, MD")

baltimore_summary = 
  baltimore_df %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

baltimore_test = prop.test(
  x = baltimore_summary %>% pull(unsolved), 
  n = baltimore_summary %>% pull(n)) 

baltimore_test %>% 
  broom::tidy()
```

As a result of this test, Baltimore, MD has a proportion of 0.646 (0.628, 0.663) unresolved crimes.


### Iteration on multiple cities estimates 

Next, I run the `prop.test()` for each of the cities in the "homicide_df" dataset. To extract both the proportion of unsolved homicides and the confidence interval for each of the cities, I follow a “tidy” pipeline which entails:.

1. **Writing a function that runs the `prop.test()` in each of the cities**. The `prop_test_unresolved` uses the "US_summary" created above (without the `knitr::kable()` chunk) and a similar structure to the equal proportions test applied to Baltimore, MD.

```{r}
prop_test_unresolved = function(homicide_df) {
  
  cities_summary = 
  homicide_df %>% 
  summarize(
    n = n(),
    unsolved = sum(resolution == "unsolved"),
      )
  
  city_test = prop.test(
    x = cities_summary %>% pull(unsolved), 
    n = cities_summary %>% pull(n))
  
  return(city_test)
}
```

2. **Iterating across all cities**. To do so, the data is first nested, then `purrr::map()` is applied indicating the list ("data") I iterate over, and the function to apply (`prop_test_homicide()`. Then, a "tidy_results" object is generated with the results, which is then unnested to select the variables of interest ("city_state", "estimate", and confidence intervals (CI)). Results are visualized below using `knitr::kable()`.

```{r}
results_df = 
  homicide_df %>% 
  nest(data = uid:resolution) %>% 
  mutate(
    test_results = map(data, prop_test_unresolved),
    tidy_results = map(test_results, broom::tidy)
  ) %>% 
  select(city_state, tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))

results_df %>% 
  knitr::kable(digits = 3)
```


### Data visualization

Finally, results as above are summarised in a plot that shows the estimates and CIs for each city. In doing so:

* Cities are reordered by estimate of unresolved crimes using `fct_reorder()`;
* Data is visualized using `ggplot()` and the scatterplot `geom_point()`;
* CIs are visualized using `geom_errorbar()`

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(
    title = "Estimated proportion of unresolved homicides and CI",
    x = "City, State",
    y = "Estimate")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```



## Problem 3

**PROMPT:** When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected – put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, you will conduct a simulation to explore power in a one-sample t-test.

### Dataset generation

First, I generate a "raw dataset" with the indicated sample size (n=30), mean (μ=0) and standard deviation (σ=5):

```{r}
raw_dataset = rnorm(30, 0, 5) %>% 
  as_tibble()
```

Next, through repeated sampling I generate 5,000 datasets. In order to do so, I will:

* create a function `norm_dataset()` that generates a dataset following a normal distribution x∼Normal[μ,σ] with the pre-set n, sd and true_mean;
* generate a "output" object which contains 5,000 lists (iterations) for each pre-set mean (0:6) with fixed sample size of n=30, and columns for the "true_mean", "sample_mean" and "p_value";
* create a `combine_function()` that runs a one-sample t-test using α=0.05 (`t.test()` within `broom::tidy()`) in each of the samples;
* generate a "result" object which contains 7 lists, one for each pre-set mean (0:6).
* 

```{r}
n = 30
sd = 5
true_mean = 0:6

norm_dataset = function(x) {
  rnorm(n, x, sd)}

output = vector("list", length = 5000)
inter <- data.frame(matrix(ncol = 3, nrow = 5000))
colnames(inter) <- c('true_mean', 'sample_mean', 'p-value')


combine_function = function(y){
  inter2 = list()
  for (i in 1:50) {
    output[[i]] = norm_dataset(y)
    a = broom::tidy(t.test(output[[i]]))
    inter[i,1] = y
    inter[i,2] = a[[1]]
    inter[i,3] = a[[3]]}
  inter2 = rbind(inter2, inter)}

result = map(true_mean, combine_function)
```


Finally, I generate a "result_df" dataframe that contains each of the 5,000 samples for the 7 given means (0:7), with the estimated sample mean, the t-test p-value result, and whether the null hypothesis is rejected (p<0.05) or not (p>=0.05).

```{r}
result_df = data.frame(c(1:5000),final[[1]])
for (i in 2:7) {
  df = data.frame(c(1:5000),final[[i]])
  result_df = rbind(result_df, df)
}

result_df = result_df %>%
  mutate(reject = ifelse(p.value < 0.05, TRUE, FALSE))
```

### Data visualization

Next , I make a plot showing the proportion of times the null (H0) was rejected on the y axis and the true value of μ on the x axis. 

```{r}
power_plot = result_df %>%
  group_by(true_mean) %>% 
  summarize(power = sum(reject)/50) %>% 
  ggplot(aes(x = true_mean, y = power)) +
  geom_point(aes(colour = true_mean)) +
  geom_line(alpha = 0.3) +
  labs(x = "True Mean", 
       y = "Proportion of times  null was rejected") +
  scale_x_continuous(breaks = seq(0,6,by = 1)) +
  scale_y_continuous(limits = c(0,1), breaks = seq(0,1,by = 0.2))
reject_plot
```


Describe the association between effect size and power ()




Next, I make a plot showing the average estimate of μ̂
 on the y axis and the true value of μ
 on the x axis. 
 
Make a second plot (or overlay on the first) the average estimate of μ̂
 only in samples for which the null was rejected on the y axis and the true value of μ
 on the x axis. 
 
Is the sample average of μ̂ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?


-------


```{r}


```
